{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ATTOU_TPCVAI_1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR5Q1Ka_9y7d"
      },
      "source": [
        "#The goal of this TP is to propose a CNN for object classification\n",
        "#We will use the newdata dataset during this TP\n",
        "#Note : You should submit the completed notebook file and\n",
        "#a pdf file describing the different results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx6nkU7NGIOt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYMkaZ-s-Noh"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch import optim\r\n",
        "from torch.nn import functional as F\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "601uvcbgDtCd",
        "outputId": "3a3313d6-3158-471e-e512-9f5a44296a7e"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFhfAiBpEM7r"
      },
      "source": [
        "%%capture\r\n",
        "!pip install wandb -q\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp_04QAqF1Hs",
        "outputId": "ae387379-9cc1-4d2e-bd5c-0e81ccb0f372"
      },
      "source": [
        "import wandb\r\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33motmattou\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2JwTmsC-QOR"
      },
      "source": [
        "%%capture\r\n",
        "!unzip Newdata.zip && mv Newdata/Test/Shape1/ Newdata/Test/Cow/ && mv Newdata/Test/Shape2/ Newdata/Test/Horse/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUwqDH_2F7x1"
      },
      "source": [
        "BATCH_SIZE = 16\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "trainset = ImageFolder('/content/Newdata/Train',transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\r\n",
        "                                          shuffle=True, num_workers=2)\r\n",
        "testset = ImageFolder('/content/Newdata/Test',transform)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\r\n",
        "                                         shuffle=False, num_workers=2)\r\n",
        "CLASS_NAMES = ('Cow', 'Horse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v0ZpgDHGB3U"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\r\n",
        "  plt.figure(figsize=(10,10))\r\n",
        "  for n in range(15):\r\n",
        "      ax = plt.subplot(5,5,n+1)\r\n",
        "      img = image_batch[n] / 2 + 0.5     # unnormalize\r\n",
        "      img = img.numpy()\r\n",
        "      plt.imshow(np.transpose(img, (1, 2, 0)))\r\n",
        "      plt.title(CLASS_NAMES[label_batch[n]])\r\n",
        "      plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC6DyFksGEQV"
      },
      "source": [
        "sample_images, sample_labels = next(iter(trainloader))\r\n",
        "show_batch(sample_images, sample_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvtP5NspIa8F"
      },
      "source": [
        "img = sample_images[1] / 2 + 0.5     # unnormalize\r\n",
        "img = img.numpy()\r\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\r\n",
        "plt.title(CLASS_NAMES[sample_labels[1]])\r\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJIE7XuD9y7k"
      },
      "source": [
        "#From scratch design a shallow CNN composed of a set of conv, pool and FC layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV8aKEzOGR-N"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras.layers import Flatten, Dense, Activation, Dropout\r\n",
        "\r\n",
        "# Je choisis d'implémenter l'architecture AlexNet du fait de sa simplicité\r\n",
        "\r\n",
        "model = keras.models.Sequential([\r\n",
        "    tf.keras.layers.Reshape(target_shape=(256,256,3),input_shape=(3,256,256)),#reshape our input to (256,256,3)\r\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(256,256,3)),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\r\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\r\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\r\n",
        "    keras.layers.BatchNormalization(),\r\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\r\n",
        "    keras.layers.Flatten(),\r\n",
        "    keras.layers.Dense(4096, activation='relu'),\r\n",
        "    keras.layers.Dropout(0.5),\r\n",
        "    keras.layers.Dense(4096, activation='relu'),\r\n",
        "    keras.layers.Dropout(0.5),\r\n",
        "    keras.layers.Dense(10, activation='sigmoid') # problem with 2 classes\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZDJiCVnRKA_"
      },
      "source": [
        "model.build()\r\n",
        "model.summary(line_length=None, positions=None, print_fn=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iZ0_xdv9y7l"
      },
      "source": [
        "#Train the model\n",
        "#Plot the error vs epoch curve\n",
        "#Report the accuracy on the test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3EdceSHQ9OH"
      },
      "source": [
        "model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpA0tBxPRX7G"
      },
      "source": [
        "sample_images, sample_labels = next(iter(trainloader))\r\n",
        "sample_images = sample_images.numpy()\r\n",
        "sample_labels = sample_labels.numpy()\r\n",
        "print(type(sample_images[1]))\r\n",
        "print(type(sample_labels[1]))\r\n",
        "print(sample_images[1].shape)\r\n",
        "print(sample_labels[1].shape)\r\n",
        "model.fit(sample_images,sample_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivc5-DANV89Y"
      },
      "source": [
        "sample_images_test, sample_labels_test = next(iter(testloader))\r\n",
        "sample_images_test = sample_images_test.numpy()\r\n",
        "sample_labels_test = sample_labels_test.numpy()\r\n",
        "model.evaluate(\r\n",
        "    x=sample_images_test, y=sample_labels_test, batch_size=28, verbose=1, sample_weight=None, steps=None,\r\n",
        "     max_queue_size=10, workers=1, use_multiprocessing=False\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjR8HIoQgJky"
      },
      "source": [
        "model.evaluate(\r\n",
        "    x=sample_images_test, y=sample_labels_test, batch_size=28, verbose=1, sample_weight=None, steps=None,\r\n",
        "     max_queue_size=10, workers=1, use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxnO04zyaaZK"
      },
      "source": [
        "### YOUR CODE HERE\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLbYlfdp9y7l"
      },
      "source": [
        "#Load in pre-trained weights from a network trained on a large dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ays0a_yQS3Dg"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\r\n",
        "\r\n",
        "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A27zfH26TAZ-"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\r\n",
        "from keras.applications.vgg16 import preprocess_input\r\n",
        "\r\n",
        "sample_images, sample_labels = next(iter(trainloader))\r\n",
        "sample_images = sample_images.numpy()\r\n",
        "sample_labels = sample_labels.numpy()\r\n",
        "\r\n",
        "sample_images = np.reshape(sample_images[0],(3,256,256))\r\n",
        "data_tf = tf.convert_to_tensor(sample_images, np.float32)\r\n",
        "print(np.shape(data_tf))\r\n",
        "#img = preprocess_input(sample_images)  # Prétraiter l'image comme le veut VGG-16\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-DI4DIadmWn"
      },
      "source": [
        "y = model.predict(data_tf)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o58H7S2O9y7m"
      },
      "source": [
        "#Extract features from the train and test images using the pre-trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne8ds0fr9y7m"
      },
      "source": [
        "#Classify the test images using a 1-nearst neighbour classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqWXAIe59y7n"
      },
      "source": [
        "#Load in pre-trained weights from a network trained on a large dataset\n",
        "#Freeze all the weights in the convolutional layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHOEtBO79y7n"
      },
      "source": [
        "#Replace the FC layers of the network with a custom classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXF8hfc39y7n"
      },
      "source": [
        "#Train only the FC layers for the object classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOgv1kJl9y7o"
      },
      "source": [
        "#Try different optimizers for the training"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}